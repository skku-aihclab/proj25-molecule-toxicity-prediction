{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Tox 21 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from collections import defaultdict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking RDKit Applicability for Tox21 Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:55:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:55:44] Explicit valence for atom # 8 Al, 6, is greater than permitted\n",
      "[01:55:44] Explicit valence for atom # 3 Al, 6, is greater than permitted\n",
      "[01:55:44] Explicit valence for atom # 4 Al, 6, is greater than permitted\n",
      "[01:55:44] Explicit valence for atom # 4 Al, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "molecules with RDKit applicability: 7823 / 7831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:55:44] Explicit valence for atom # 9 Al, 6, is greater than permitted\n",
      "[01:55:44] Explicit valence for atom # 5 Al, 6, is greater than permitted\n",
      "[01:55:44] Explicit valence for atom # 16 Al, 6, is greater than permitted\n",
      "[01:55:45] Explicit valence for atom # 20 Al, 6, is greater than permitted\n"
     ]
    }
   ],
   "source": [
    "# Load tox21 dataset\n",
    "df = pd.read_csv(\"tox21.csv\")\n",
    "\n",
    "# check if RDKit can be applied to the molecules in the dataset\n",
    "def apply_rdkit(smiles):\n",
    "    return Chem.MolFromSmiles(smiles) is not None\n",
    "    \n",
    "\n",
    "total = len(df)\n",
    "available = df[\"smiles\"].apply(apply_rdkit).sum()\n",
    "\n",
    "print(f\"molecules with RDKit applicability: {available} / {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save the filtered dataset into refined_tox21.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:55:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:55:50] Explicit valence for atom # 8 Al, 6, is greater than permitted\n",
      "[01:55:50] Explicit valence for atom # 3 Al, 6, is greater than permitted\n",
      "[01:55:50] Explicit valence for atom # 4 Al, 6, is greater than permitted\n",
      "[01:55:50] Explicit valence for atom # 4 Al, 6, is greater than permitted\n",
      "[01:55:50] Explicit valence for atom # 9 Al, 6, is greater than permitted\n",
      "[01:55:50] Explicit valence for atom # 5 Al, 6, is greater than permitted\n",
      "[01:55:50] Explicit valence for atom # 16 Al, 6, is greater than permitted\n",
      "[01:55:50] Explicit valence for atom # 20 Al, 6, is greater than permitted\n"
     ]
    }
   ],
   "source": [
    "valid_df = df[df[\"smiles\"].apply(apply_rdkit)].copy()\n",
    "valid_df.to_csv(\"refined_tox21.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a 13C-NMR Spectrum Dataset for Available Tox21 Molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Converting SMILES Strings to InChIKeys for Spectral Data Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:40:20] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "mol_id_list = []\n",
    "inchikey_list = []\n",
    "\n",
    "for idx, row in valid_df.iterrows():\n",
    "    mol_id = row['mol_id']\n",
    "    smiles = row['smiles']\n",
    "    \n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        inchikey = Chem.MolToInchiKey(mol)\n",
    "        \n",
    "        # Only add to lists if InChIKey is valid\n",
    "        if inchikey is not None:\n",
    "            mol_id_list.append(mol_id)\n",
    "            inchikey_list.append(inchikey)\n",
    "        \n",
    "    else:\n",
    "        inchikey = None\n",
    "        print(f\"Invalid SMILES: {smiles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save the output as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only leave mol id and inchikey\n",
    "df_inchikey = pd.DataFrame({\n",
    "    'mol_id': mol_id_list,\n",
    "    'InChIKey': inchikey_list,\n",
    "})\n",
    "\n",
    "#remove duplicates\n",
    "df_inchikey = df_inchikey.drop_duplicates(subset=['InChIKey'])\n",
    "\n",
    "df_inchikey.to_csv('tox21_inchikey.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7821"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_inchikey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Collecting 13C-NMR Spectral Data for Tox21 Molecules in NMRShiftDB2 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db2_sdf_path = \"NmrShift/nmrshiftdb2withsignals.sd\" # path to NMRShiftdb2 SDF file\n",
    "with open(db2_sdf_path, 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Split the content by \"$$$$\" to get individual molecules\n",
    "molecules = content.split(\"$$$$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 13C NMR spectrum in NMRShift: 33005.\n"
     ]
    }
   ],
   "source": [
    "# extract NMR spectra and InChI keys from NMRShift\n",
    "spectra_dict = {}\n",
    "for block in molecules:\n",
    "    lines = block.splitlines()\n",
    "    ik = None\n",
    "    spec = None\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        if line == \"> <INChI key>\":    \n",
    "            if i + 1 < len(lines):\n",
    "                ik = lines[i+1].strip()\n",
    "        elif line == \"> <Spectrum 13C 0>\":\n",
    "            if i + 1 < len(lines):\n",
    "                spec = lines[i+1].strip()\n",
    "        # end if both found\n",
    "        if ik and spec:\n",
    "            spectra_dict[ik] = spec\n",
    "            break\n",
    "\n",
    "print(f\"total 13C NMR spectrum in NMRShift: {len(spectra_dict)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save each molecule’s binary spectrum vector, indicating presence (1) or absence (0) of 13C NMR peaks at 0.1 ppm intervals from –50 to 350 ppm, as a NumPy array in a npy file named by its molecule ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved total 2254 binary spectra to 'spectra'\n"
     ]
    }
   ],
   "source": [
    "# parameters for binary vector\n",
    "min_value, max_value, scale = -50.0, 350.0, 10  # 0.1 ppm intervals\n",
    "units = int((max_value - min_value) * scale)   # 4000 dimension binary vector\n",
    "\n",
    "spectra_dir = \"spectra\" # output directory for binary spectra\n",
    "os.makedirs(spectra_dir, exist_ok=True)\n",
    "\n",
    "# For each molecule, extract the InChIKey and corresponding spectrum\n",
    "# convert the spectrum to a binary vector, and save it as a .npy file.\n",
    "for _, row in df_inchikey.iterrows():\n",
    "    ik     = row[\"InChIKey\"]\n",
    "    mol_id = row[\"mol_id\"]\n",
    "    spec_str = spectra_dict.get(ik)\n",
    "    if not spec_str:\n",
    "        continue\n",
    "\n",
    "    # extract ppm values from the spectrum string\n",
    "    indices = []\n",
    "    for entry in spec_str.split(\"|\"):\n",
    "        if not entry: continue\n",
    "        try:\n",
    "            ppm = float(entry.split(\";\",1)[0]) # ppm value is before the first semicolon\n",
    "        except ValueError:\n",
    "            continue\n",
    "        idx = int(round((ppm - min_value) * scale)) # convert ppm to index\n",
    "        if 0 <= idx < units:\n",
    "            indices.append(idx)\n",
    "\n",
    "    if not indices:\n",
    "        continue\n",
    "\n",
    "    # create a binary vector of size 4000\n",
    "    vec = np.zeros(units, dtype=np.uint8)\n",
    "    vec[indices] = 1\n",
    "\n",
    "    save_path = os.path.join(spectra_dir, f\"{mol_id}.npy\")\n",
    "    np.save(save_path, vec)\n",
    "\n",
    "print(f\"Saved total {len(os.listdir(spectra_dir))} binary spectra to '{spectra_dir}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Collecting 13C-NMR Spectral Data for Tox21 Molecules in NP-MRD database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1551 NP-MRD compound data matched with Tox21 dataset.\n"
     ]
    }
   ],
   "source": [
    "json_pattern = os.path.join(\"npmrd_natural_products_json\", \"*.json\") # json file which contains InChIKey and NP-MRD ID(accession) of NP-MRD database\n",
    "json_files = glob.glob(json_pattern)\n",
    "\n",
    "# map inchikey to NP-MRD ID(accession)\n",
    "inchikey2acc = {}\n",
    "for js in json_files:\n",
    "    with open(js, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    for entry in data[\"np_mrd\"][\"natural_product\"]:\n",
    "        ik  = entry.get(\"inchikey\")\n",
    "        acc = entry.get(\"accession\")\n",
    "        if ik and acc:\n",
    "            inchikey2acc[ik] = acc\n",
    "\n",
    "df_inchikey[\"accession\"] = df_inchikey[\"InChIKey\"].map(inchikey2acc)\n",
    "\n",
    "matched = df_inchikey[\"accession\"].notna().sum()\n",
    "print(f\"{matched} NP-MRD compound data matched with Tox21 dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing = {\n",
    "    os.path.splitext(fname)[0]\n",
    "    for fname in os.listdir(spectra_dir)\n",
    "    if fname.endswith(\".npy\")\n",
    "}\n",
    "\n",
    "df_acc = df_inchikey[df_inchikey[\"accession\"].notna()]\n",
    "\n",
    "# find which mol_id is already covered by existing spectra\n",
    "covered = df_acc[\"mol_id\"].astype(str).isin(existing)\n",
    "\n",
    "# map mol_id to NP-MRD ID\n",
    "acc2mol = dict(zip(df_inchikey[\"accession\"], df_inchikey[\"mol_id\"]))\n",
    "to_add_acc = df_acc.loc[~covered, \"accession\"].unique() # list of NP-MRD IDs that need spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of directories which contain NP-MRD peak lists in txt format\n",
    "configs = [\n",
    "    (\"NP-MRD_nmr_peak_lists/NP-MRD_nmr_peak_lists_*\", \"{acc}_*.txt\"),\n",
    "    (\"NP-MRD_assignment_tables\", \"*_{acc}_*.txt\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the NP-MRD peak lists to find spectra\n",
    "for acc in to_add_acc:\n",
    "    for base_dir, file_pat in configs:\n",
    "        pattern = os.path.join(base_dir, file_pat.format(acc=acc))\n",
    "        files = glob.glob(pattern)\n",
    "        if not files:\n",
    "            continue\n",
    "\n",
    "        indices = []\n",
    "        with open(files[0], \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                # conditions that contain 13C NMR spectra\n",
    "                parts = re.split(r\"[,\\t]+\", line.strip())\n",
    "                if len(parts) < 3: # must have at least 3 columns\n",
    "                    continue\n",
    "                if parts[0] != \"C\" and parts[1] != \"C\": # not a carbon spectrum\n",
    "                    continue\n",
    "                ppm_str = parts[2] # ppm value is in the third column\n",
    "                if ppm_str in (\"\", \"NA\"):\n",
    "                    continue\n",
    "                try:\n",
    "                    ppm = float(ppm_str) # convert ppm string to float\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "                idx = int(round((ppm - min_value) * scale)) # convert ppm index\n",
    "                if 0 <= idx < units:\n",
    "                    indices.append(idx)\n",
    "\n",
    "        if not indices:\n",
    "            continue\n",
    "\n",
    "        # create a binary vector\n",
    "        vec = np.zeros(units, dtype=np.uint8)\n",
    "        vec[indices] = 1\n",
    "        mol_id = acc2mol.get(acc, acc)\n",
    "        save_path = os.path.join(spectra_dir, f\"{mol_id}.npy\") # save the binary vector as a .npy file\n",
    "        np.save(save_path, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved total 2771 binary spectra to 'spectra'\n"
     ]
    }
   ],
   "source": [
    "for acc in to_add_acc:\n",
    "    pattern = os.path.join(\"NP-MRD_peak_lists_unassigned\", f\"{acc}_*peak_list*.csv\") # NP-MRD peak lists in CSV format\n",
    "    files = glob.glob(pattern)\n",
    "    if not files:\n",
    "        continue\n",
    "\n",
    "    txt_path = files[0]\n",
    "    indices = []\n",
    "    \n",
    "\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            # conditions that contain 13C NMR spectra\n",
    "            parts = re.split(r\"[,\\t ]+\", line.strip())\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            if parts[0] != \"C\": # first column must be 'C' for carbon spectrum\n",
    "                continue\n",
    "            ppm_str = parts[1] # ppm value is in the second column\n",
    "            if ppm_str in (\"\", \"NA\"):\n",
    "                continue\n",
    "            try:\n",
    "                ppm = float(ppm_str) # convert ppm string to float\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            idx = int(round((ppm - min_value) * scale)) # convert ppm to index\n",
    "            if 0 <= idx < units:\n",
    "                indices.append(idx)\n",
    "\n",
    "    if not indices:\n",
    "        continue\n",
    "\n",
    "    # create a binary vector\n",
    "    vec = np.zeros(units, dtype=np.uint8)\n",
    "    vec[indices] = 1\n",
    "\n",
    "    mol_id = acc2mol.get(acc, acc)\n",
    "    save_path = os.path.join(spectra_dir, f\"{mol_id}.npy\")\n",
    "    np.save(save_path, vec)\n",
    "\n",
    "print(f\"Saved total {len(os.listdir(spectra_dir))} binary spectra to '{spectra_dir}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Collecting 13C-NMR Spectral Data for Tox21 Molecules in HMDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmdb_sdf_path = \"HMDB_structures/structures.sdf\" # sdf file wich contains InChIKey and HMDB ID of HMDB database\n",
    "with open(hmdb_sdf_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    blocks = f.read().split(\"$$$$\")\n",
    "\n",
    "# map InChIKey to HMDB ID\n",
    "inchikey2dbid = {}\n",
    "for blk in blocks:\n",
    "    lines = blk.splitlines()\n",
    "    ik = dbid = None\n",
    "    for i, L in enumerate(lines):\n",
    "        L = L.strip()\n",
    "        if L == \"> <INCHI_KEY>\" and i+1 < len(lines):\n",
    "            ik = lines[i+1].strip()\n",
    "        elif L == \"> <DATABASE_ID>\" and i+1 < len(lines):\n",
    "            dbid = lines[i+1].strip()\n",
    "        if ik and dbid:\n",
    "            inchikey2dbid[ik] = dbid\n",
    "            break\n",
    "\n",
    "df_inchikey[\"HMDB_ID\"] = df_inchikey[\"InChIKey\"].map(inchikey2dbid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of existing spectra after adding NP-MRD\n",
    "existing = {\n",
    "    os.path.splitext(f)[0]\n",
    "    for f in os.listdir(spectra_dir)\n",
    "    if f.endswith(\".npy\")\n",
    "}\n",
    "\n",
    "mask_hmdb   = df_inchikey[\"HMDB_ID\"].notna()\n",
    "mask_exists = df_inchikey[\"mol_id\"].astype(str).isin(existing)\n",
    "missing_spec = df_inchikey[mask_hmdb & ~mask_exists] # list of HDMB IDs that need spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved total 2851 binary spectra to 'spectra'\n"
     ]
    }
   ],
   "source": [
    "# iterate through the missing HMDB spectra to find matching XML files\n",
    "for _, row in missing_spec.iterrows():\n",
    "    mol_id  = row[\"mol_id\"]\n",
    "    hmdb_id = row[\"HMDB_ID\"]\n",
    "    \n",
    "    # search for XML files which match the HMDB IDs that need spectra\n",
    "    pattern = os.path.join(\"hmdb_nmr_spectra\", f\"{hmdb_id}_nmr_one_d_spectrum_*.xml\")\n",
    "    files = glob.glob(pattern)\n",
    "    if not files:\n",
    "        continue\n",
    "\n",
    "    shifts = []\n",
    "    indices = []\n",
    "    for xml_path in files:\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        notes = root.findtext(\"notes\", default=\"\").lower()\n",
    "        if \"13c spectrum\" not in notes: # no 13C spectrum in this XML\n",
    "            continue\n",
    "\n",
    "        for peak in root.findall(\".//nmr-one-d-peak\"): # 13C spectrum peaks\n",
    "            cs = peak.findtext(\"chemical-shift\")\n",
    "            if not cs:\n",
    "                continue\n",
    "            try:\n",
    "                ppm = float(cs) # convert ppm to float\n",
    "            except ValueError:\n",
    "                continue\n",
    "            shifts.append(ppm)\n",
    "        break\n",
    "\n",
    "    if not shifts:\n",
    "        continue\n",
    "\n",
    "    indices = [\n",
    "        idx for ppm in shifts\n",
    "        if 0 <= (idx := int(round((ppm - min_value) * scale))) < units # convert ppm to index\n",
    "    ]\n",
    "\n",
    "    if not indices:\n",
    "        continue\n",
    "\n",
    "    # create a binary vector\n",
    "    vec = np.zeros(units, dtype=np.uint8)\n",
    "    vec[indices] = 1\n",
    "    save_path = os.path.join(spectra_dir, f\"{mol_id}.npy\")\n",
    "    np.save(save_path, vec)\n",
    "\n",
    "print(f\"Saved total {len(os.listdir(spectra_dir))} binary spectra to '{spectra_dir}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* These npy files represent the 1D NMR modality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Molecular Image Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate 224×224 PNG images of molecules from SMILES strings in the refined Tox21 dataset using RDKit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:39:51] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7823 molecules saved to images\n"
     ]
    }
   ],
   "source": [
    "img_dir = \"images\" # output directory for molecule images\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "count = 0\n",
    "\n",
    "# save images of molecules\n",
    "for mol_id, smi in zip(valid_df[\"mol_id\"], valid_df[\"smiles\"]):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    out_path = os.path.join(img_dir, f\"{mol_id}.png\")\n",
    "    # skip if mol is None\n",
    "    if mol is None:\n",
    "        print(f\"Invalid SMILES: {smi}\")\n",
    "        continue\n",
    "    Draw.MolToFile(mol, out_path, size=(224, 224))\n",
    "    count += 1\n",
    "    \n",
    "print(f\"total {count} molecules saved to {img_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* These png files represent the 2D CNN modality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate train, validation, test splits using scaffold, and corresponding spectral datasets for each split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Replace missing labels with –1 to facilitate masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"NR-AR\",\"NR-AR-LBD\",\"NR-AhR\",\"NR-Aromatase\",\n",
    "    \"NR-ER\",\"NR-ER-LBD\",\"NR-PPAR-gamma\",\n",
    "    \"SR-ARE\",\"SR-ATAD5\",\"SR-HSE\",\"SR-MMP\",\"SR-p53\"\n",
    "]\n",
    "valid_df[labels] = valid_df[labels].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate scaffold from SMILES\n",
    "def generate_scaffold(smiles, include_chirality=False):\n",
    "    scaffold = MurckoScaffold.MurckoScaffoldSmiles(\n",
    "        smiles=smiles, includeChirality=include_chirality)\n",
    "    return scaffold\n",
    "\n",
    "# Function to split dataset into train, validation, and test sets based on scaffold\n",
    "def scaffold_split(index, smiles_list, frac_train=0.8, frac_valid=0.1, frac_test=0.1,\n",
    "                                         sort=False, seed=None):\n",
    "    \"\"\"\n",
    "    Split the dataset into train, validation, and test sets based on scaffold.\n",
    "    Args:\n",
    "        index: Sequence of indices for the dataset.\n",
    "        smiles_list: List of SMILES strings corresponding to the dataset.\n",
    "        frac_train/frac_valid/frac_test: Fractions that (approximately) sum to 1.0.\n",
    "        sort: If True, sort split indices ascending before returning.\n",
    "        seed: Random seed for reproducibility.\n",
    "    \"\"\"\n",
    "\n",
    "    index = np.array(index)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Build scaffold buckets\n",
    "    scaffolds = defaultdict(list)\n",
    "    for ind, smiles in enumerate(smiles_list):\n",
    "        scaffold = generate_scaffold(smiles, include_chirality=False)\n",
    "        scaffolds[scaffold].append(ind)\n",
    "\n",
    "    # Shuffle the scaffold groups\n",
    "    scaffold_sets = rng.permutation(np.array(list(scaffolds.values()), dtype=object))\n",
    "\n",
    "    # target sizes\n",
    "    n_total = len(index)\n",
    "    n_total_train = int(np.floor(frac_train * n_total))\n",
    "    n_total_valid = int(np.floor(frac_valid * n_total))\n",
    "    n_total_test  = int(np.floor(frac_test  * n_total))\n",
    "\n",
    "    train_idx, valid_idx, test_idx = [], [], []\n",
    "    counts  = {\"train\": 0, \"valid\": 0, \"test\": 0}\n",
    "    targets = {\"train\": n_total_train, \"valid\": n_total_valid, \"test\": n_total_test}\n",
    "\n",
    "    # Assign each scaffold groups to the split with the largest deficit\n",
    "    for g in scaffold_sets:\n",
    "        deficits = {k: targets[k] - counts[k] for k in (\"train\", \"valid\", \"test\")}\n",
    "        max_def = max(deficits.values())\n",
    "        candidates = [k for k, v in deficits.items() if v == max_def]\n",
    "        dest = rng.choice(candidates) # Randomly select a destination split if there is a tie\n",
    "        if dest == \"train\":\n",
    "            train_idx.extend(g); counts[\"train\"] += len(g)\n",
    "        elif dest == \"valid\":\n",
    "            valid_idx.extend(g); counts[\"valid\"] += len(g)\n",
    "        else:\n",
    "            test_idx.extend(g);  counts[\"test\"]  += len(g)\n",
    "\n",
    "    train_index, val_index, test_index = index[train_idx], index[valid_idx], index[test_idx]\n",
    "\n",
    "    if sort:\n",
    "        train_index = sorted(train_index)\n",
    "        val_index = sorted(val_index)\n",
    "        test_index = sorted(test_index)\n",
    "\n",
    "    return train_index, val_index, test_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:34:56] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "# Generate scaffold-based splits\n",
    "index = valid_df.index.values\n",
    "smiles_list = valid_df[\"smiles\"].tolist() \n",
    "\n",
    "train_idx, val_idx, test_idx = scaffold_split(\n",
    "    index=index,\n",
    "    smiles_list=smiles_list,\n",
    "    frac_train=0.8,\n",
    "    frac_valid=0.1,\n",
    "    frac_test=0.1,\n",
    ")\n",
    "\n",
    "df_train = valid_df.loc[train_idx].reset_index(drop=True)\n",
    "df_val   = valid_df.loc[val_idx].reset_index(drop=True)\n",
    "df_test  = valid_df.loc[test_idx].reset_index(drop=True)\n",
    "\n",
    "# Save the splits to CSV files\n",
    "df_train.to_csv(\"train.csv\", index=False)\n",
    "df_val.to_csv(\"valid.csv\", index=False)\n",
    "df_test.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create train/valid/test data splits containing only molecules with available spectral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of mol_id values from the spectra directory\n",
    "spectra_dir = \"spectra\"\n",
    "all_specs = {\n",
    "    os.path.splitext(fn)[0]\n",
    "    for fn in os.listdir(spectra_dir)\n",
    "    if fn.endswith(\".npy\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train_spectra.csv: 2452/6258 samples\n",
      "Saved valid_spectra.csv: 194/781 samples\n",
      "Saved test_spectra.csv: 205/784 samples\n"
     ]
    }
   ],
   "source": [
    "# filter for mol_ids with available spectrum data\n",
    "train_spectra_df = df_train[df_train[\"mol_id\"].isin(all_specs)].copy()\n",
    "train_spectra_df.to_csv(\"train_spectra.csv\", index=False)\n",
    "print(f\"Saved train_spectra.csv: {len(train_spectra_df)}/{len(df_train)} samples\")\n",
    "\n",
    "valid_spectra_df = df_val[df_val[\"mol_id\"].isin(all_specs)].copy()\n",
    "valid_spectra_df.to_csv(\"valid_spectra.csv\", index=False)\n",
    "print(f\"Saved valid_spectra.csv: {len(valid_spectra_df)}/{len(df_val)} samples\")\n",
    "\n",
    "test_spectra_df = df_test[df_test[\"mol_id\"].isin(all_specs)].copy()\n",
    "test_spectra_df.to_csv(\"test_spectra.csv\", index=False)\n",
    "print(f\"Saved test_spectra.csv: {len(test_spectra_df)}/{len(df_test)} samples\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
